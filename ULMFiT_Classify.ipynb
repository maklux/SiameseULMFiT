{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULMFiT + Siamese Network for Sentence Vectors\n",
    "## Part Three: Classifying\n",
    "\n",
    "This notebook will use the German Language Model, created in the previous one, to predict categories based on Office FAQ entries. The model will be used as a sentence encoder for a Siamese Network that builds sentence vectors that are feed into a classifier network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to load fastai library\n",
    "import sys\n",
    "sys.path.append(\"/data/home/makayser/notebooks/fastai/\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "# from fastai.lm_rnn import *\n",
    "from fastai.text import *\n",
    "import html\n",
    "\n",
    "#temp fix\n",
    "#from old.fastai import lm_rnn as old_lm_rnn\n",
    "\n",
    "import json\n",
    "import html\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from functools import partial\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import dataset, dataloader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/home/makayser/qa_local/'\n",
    "token_files = data_dir + 'token/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new dataloader to create sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataLoader():\n",
    "    def __init__(self, sentence_pairs, pad_val, batch_size=32):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "        self.pad_val = pad_val\n",
    "     \n",
    "    def shuffle(self):\n",
    "        def srtfn(x):\n",
    "            return x[:, -1] + random.randint(-5, 5)\n",
    "        \n",
    "        order = np.argsort(srtfn(self.sentence_pairs))\n",
    "        self.sentence_pairs = self.sentence_pairs[order]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def fill_tensor(self, sentences, max_len):\n",
    "        data = np.zeros((max_len, len(sentences)), dtype=np.long)\n",
    "        data.fill(self.pad_val)\n",
    "        \n",
    "        for i, s in enumerate(sentences): \n",
    "            start_idx = max_len - len(s)\n",
    "            for j, p in enumerate(s):\n",
    "                data[:,i][start_idx+j] = p\n",
    "            \n",
    "        return torch.LongTensor([data.tolist()]).cuda()\n",
    "     \n",
    "    def batch(self):\n",
    "        return self.index//self.batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentence_pairs)//self.batch_size\n",
    "    \n",
    "    def __next__(self):\n",
    "        #how many examples to ananlyise for this round\n",
    "        num = min(self.batch_size, len(self.sentence_pairs) - self.index)\n",
    "        \n",
    "        if num < 1:\n",
    "            raise StopIteration  # signals \"the end\"\n",
    "            \n",
    "        #collect the sentences\n",
    "        max_len_a = 0\n",
    "        max_len_b = 0\n",
    "        first = []\n",
    "        second = []\n",
    "        labels = torch.LongTensor(num)\n",
    "        \n",
    "        for i in range(num):\n",
    "            a, b, l, _ = self.sentence_pairs[self.index + i]\n",
    "            \n",
    "            if len(a) > max_len_a:\n",
    "                max_len_a = len(a)\n",
    "            \n",
    "            if len(b) > max_len_b:\n",
    "                max_len_b = len(b)\n",
    "            \n",
    "            first.append(a)\n",
    "            second.append(b)\n",
    "            labels[i] = l \n",
    "            \n",
    "        self.index += num\n",
    "        \n",
    "        first = self.fill_tensor(first, max_len_a)\n",
    "        second = self.fill_tensor(second, max_len_b)\n",
    "        return (first.cuda(),\n",
    "                (first != self.pad_val).cuda(),\n",
    "                second.cuda(),\n",
    "                (second != self.pad_val).cuda(),\n",
    "                labels.cuda()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n",
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n",
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n"
     ]
    }
   ],
   "source": [
    "itos = pickle.load(open(f'{token_files}itos.pkl', 'rb'))\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "vocab_size = len(itos)\n",
    "pad_tok = stoi['_pad_']\n",
    "\n",
    "sentence_pairs_train = np.load(f'{token_files}office_tok_train.npy')\n",
    "sentence_pairs_dev = np.load(f'{token_files}office_tok_dev.npy')\n",
    "sentence_pairs_test = np.load(f'{token_files}office_tok_test.npy')\n",
    "\n",
    "def print_sentence(s):\n",
    "    sentence = \"\"\n",
    "    for tok in s:\n",
    "        sentence += \" \"+itos[tok]\n",
    "    print(sentence)\n",
    "\n",
    "print_sentence(sentence_pairs_train[0][0])\n",
    "print_sentence(sentence_pairs_train[0][1])\n",
    "\n",
    "print_sentence(sentence_pairs_dev[0][0])\n",
    "print_sentence(sentence_pairs_dev[0][1])\n",
    "\n",
    "print_sentence(sentence_pairs_test[0][0])\n",
    "print_sentence(sentence_pairs_test[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 51, 7, 2618, 9, 1526, 8, 27, 125, 238]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'der'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_bos ändern der anzeigesprache und zeitzone in office 365 business \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der anzeige von einem 3d-diagramm \n",
      "x_bos ändern der arbeitszeiten und arbeitstage in outlook \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n",
      "x_bos ändern der darstellung der diagrammachsen \n"
     ]
    }
   ],
   "source": [
    "training_data = SiameseDataLoader(sentence_pairs_train, pad_tok)\n",
    "for batch in training_data:\n",
    "    sentences = batch[0][0]\n",
    "    masks = batch[1][0]\n",
    "    for sentence, mask in zip(sentences.transpose(1,0), masks.transpose(1,0)):\n",
    "        for tok in torch.masked_select(sentence, mask):\n",
    "            print(itos[int(tok)], end=' ')\n",
    "        print(\"\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the masking and pooling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.]])\n",
      "tensor([2., 2., 2., 2.])\n",
      "tensor([[4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.]])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([[ 7.,  7.,  7.,  7.],\n",
      "        [ 8.,  8.,  8.,  8.],\n",
      "        [ 9.,  9.,  9.,  9.],\n",
      "        [10., 10., 10., 10.]])\n",
      "tensor([10., 10., 10., 10.])\n",
      "tensor([[1.5000, 1.5000, 1.5000, 1.5000],\n",
      "        [5.0000, 5.0000, 5.0000, 5.0000],\n",
      "        [8.5000, 8.5000, 8.5000, 8.5000]])\n"
     ]
    }
   ],
   "source": [
    "# sentences are in the form [sentence_length, batch_size, embedding_size]\n",
    "# masks are in the form [sentence_length, batch_size])\n",
    "sentence_length = 5\n",
    "batch_size = 3\n",
    "embedding_size = 4\n",
    "\n",
    "out = torch.zeros((batch_size, embedding_size))\n",
    "sentences = torch.tensor([ \n",
    "                    [[1,1,1,1], [4,4,4,4], [7,7,7,7]],\n",
    "                    [[2,2,2,2], [5,5,5,5], [8,8,8,8]],\n",
    "                    [[0,0,0,0], [6,6,6,6], [9,9,9,9]],\n",
    "                    [[0,0,0,0], [0,0,0,0], [10,10,10,10]],\n",
    "                    [[0,0,0,0], [0,0,0,0], [0,0,0,0]]\n",
    "                    ]).float()\n",
    "\n",
    "#sentences.shape == [5, 3, 4]\n",
    "\n",
    "masks = torch.tensor([[[1,1,1], [1,1,1], [0,1,1], [0,0,1], [0,0,0]]]).byte()\n",
    "#masks.shape == [1, 5, 3]\n",
    "\n",
    "for i, sentence, mask in zip(range(batch_size), sentences.permute((1,0,2)), masks.squeeze().permute(1,0)):\n",
    "    mask = mask.unsqueeze(1)\n",
    "    selected = torch.masked_select(sentence, mask)\n",
    "    selected = torch.reshape(selected, (-1, embedding_size))\n",
    "    print(selected)\n",
    "    max = torch.max(selected, 0)[0]\n",
    "    print(max)\n",
    "    out[i] = torch.mean(selected, 0)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, linear):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.linear = linear\n",
    "    \n",
    "    def pool(self, x, masks, is_max):\n",
    "        #x.shape = sentence length, batch size, embedding size\n",
    "        #mask.shape = [1, sentence length, batch size]\n",
    "        \n",
    "        embedding_size = x.shape[2]\n",
    "        batch_size = x.shape[1]\n",
    "        out = torch.zeros((batch_size, embedding_size)).cuda()\n",
    "        masks = masks.squeeze()\n",
    "        #print(f'shapes: x {x.shape}, masks {masks.shape}, out {out.shape}')\n",
    "        \n",
    "        #shapes: x torch.Size([7, 32, 400]), mask torch.Size([7, 32]), out torch.Size([32, 400])\n",
    "                \n",
    "        for i, hidden, mask in zip(range(batch_size), x.permute((1,0,2)), masks.permute(1,0)):\n",
    "            mask = mask.unsqueeze(1)\n",
    "            selected = torch.masked_select(hidden, mask)\n",
    "            selected = torch.reshape(selected, (-1, embedding_size))\n",
    "            if is_max:\n",
    "                max_pool = torch.max(selected, 0)[0]\n",
    "                out[i] = max_pool\n",
    "            else:\n",
    "                mean_pool = torch.mean(selected, 0)\n",
    "                out[i] = mean_pool\n",
    "\n",
    "        return out\n",
    "\n",
    "    def pool_outputs(self, output, mask):\n",
    "        avgpool = self.pool(output, mask, False)\n",
    "        maxpool = self.pool(output, mask, True)\n",
    "        last = output[-1]\n",
    "        return torch.cat([last, maxpool, avgpool], 1)\n",
    "        \n",
    "    def forward_once(self, input, mask):\n",
    "        raw_outputs, outputs = self.encoder(input)\n",
    "        out = self.pool_outputs(outputs[-1], mask)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, in1, in1_mask, in2, in2_mask):\n",
    "        u = self.forward_once(in1, in1_mask)\n",
    "        v = self.forward_once(in2, in2_mask)\n",
    "        features = torch.cat((u, v, torch.abs(u-v), u*v), 1)\n",
    "        out = self.linear(features)\n",
    "        return out \n",
    "        \n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, layers, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([LinearBlock(layers[i], layers[i + 1], dropout) for i in range(len(layers) - 1)])\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for l in self.layers:\n",
    "            l_x = l(x)\n",
    "            x = F.relu(l_x)\n",
    "        return l_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the values used for the original LM\n",
    "em_sz, nh, nl = 300, 1150, 3 #400\n",
    "bptt = 70\n",
    "max_seq = bptt * 20\n",
    "cats = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our pretrained model then build the Siamese network from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "This should be converted over to the fast.ai learner but I'm not sure how to do that yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.\n",
    "    num_correct = 0\n",
    "    total = 0 \n",
    "    \n",
    "    for x in data_loader:\n",
    "        a = x[0]\n",
    "        a_mask = x[1]\n",
    "        b = x[2]\n",
    "        b_mask = x[3]\n",
    "        l = x[4]\n",
    "        \n",
    "        if b.size(1) > 1450:\n",
    "            print('rejected:', b.size())\n",
    "            continue\n",
    "        \n",
    "        model.reset()\n",
    "        out = model(a.squeeze(), a_mask.squeeze(), b.squeeze(), b_mask.squeeze()) # squeezed the masks\n",
    "        loss = criterion(out, l.squeeze())\n",
    "        total += l.size(0)\n",
    "        total_loss += l.size(0) * loss.item()\n",
    "        num_correct += np.sum(l.data.cpu().numpy() == np.argmax(out.data.cpu().numpy(), 1))\n",
    "        \n",
    "    return (total_loss / total, num_correct / total)\n",
    "\n",
    "def train(model, data_loader, optimizer):\n",
    "    # Turn on training mode which enables dropout.\n",
    "    start_time = time.time()\n",
    "    model.train() \n",
    "    \n",
    "    total_loss = 0.\n",
    "    num_correct = 0\n",
    "    total = 0 \n",
    "        \n",
    "    for x in data_loader:\n",
    "        a = x[0]\n",
    "        a_mask = x[1]\n",
    "        b = x[2]\n",
    "        b_mask = x[3]\n",
    "        l = x[4]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if b.size(1) > 1450:\n",
    "            print('rejected:', b.size())\n",
    "            continue\n",
    "        \n",
    "        model.reset()\n",
    "        #torch.Size([1, 7, 32])\n",
    "        \n",
    "        out = model(a.squeeze(), a_mask.squeeze(), b.squeeze(), b_mask.squeeze()) #squeezed the masks\n",
    "        loss = criterion(out, target=l.squeeze())\n",
    "        total += l.size(0)\n",
    "        total_loss += l.size(0) * loss.item()\n",
    "        num_correct += np.sum(l.data.cpu().numpy() == np.argmax(out.data.cpu().numpy(), 1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch = data_loader.batch()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / total\n",
    "            elapsed = time.time() - start_time\n",
    "            batches = len(data_loader)\n",
    "            ms = elapsed * 1000 / log_interval\n",
    "            print(f'| {batch:5d}/{batches:5d} batches', end=\" \")\n",
    "            print(f'| ms/batch {ms:5.2f} | loss {cur_loss:5.4f} acc {num_correct / total}')\n",
    "            #print(f'| ms/batch {ms:5.2f} | loss {cur_loss:5.4f}')\n",
    "            total_loss = 0\n",
    "            total = 0\n",
    "            num_correct = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 100\n",
    "def training_loop(model, epochs, optimizer, scheduler = None):\n",
    "    \n",
    "    global best_loss\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f'Start epoch {epoch:3d} training with lr ', end=\"\")\n",
    "        for g in optimizer.param_groups:\n",
    "            print(g['lr'], end=\" \")\n",
    "        print(\"\")\n",
    "        \n",
    "        training_data = SiameseDataLoader(sentence_pairs_train, pad_tok)\n",
    "        training_data.shuffle()\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train(model, training_data, optimizer)\n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "        dev_data = SiameseDataLoader(sentence_pairs_dev, pad_tok)\n",
    "        val_loss, accuracy = evaluate(model, dev_data)\n",
    "\n",
    "        delta_t = (time.time() - epoch_start_time)\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {delta_t:5.2f}s | valid loss {val_loss:5.2f} accuracy {accuracy} learning rates')\n",
    "        for g in optimizer.param_groups:\n",
    "            print(g['lr'])\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            with open(f'./siamese_model{val_loss:0.2f}{accuracy:0.2f}.pt', 'wb') as f:\n",
    "                torch.save(siamese_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filtfilt(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def plot_loss(losses):\n",
    "    plt.semilogx(losses[:,0], losses[:,1])\n",
    "    plt.semilogx(losses[:,0], butter_lowpass_filtfilt(losses[:,1], 300, 5000))\n",
    "    plt.show()\n",
    "\n",
    "def find_lr(model, model_to_optim, data_loader):\n",
    "    losses = []\n",
    "    model.train() \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr = 0.00001\n",
    "    for x in data_loader: #a, b, l\n",
    "        a = x[0]#; print(a.size(), a.squeeze().size())\n",
    "        a_m = x[1]#; print(a_m.size())\n",
    "        b = x[2]#; print(b.size(), b.squeeze().size())\n",
    "        b_m = x[3]#; print(b_m.size(), '\\n*')\n",
    "        l = x[4]\n",
    "        \n",
    "        if b.size(1) > 1450:\n",
    "            #NOTE: bug where \n",
    "#             torch.Size([1, 11, 32]) torch.Size([11, 32])\n",
    "#             torch.Size([1, 11, 32])\n",
    "#             torch.Size([1, 1568, 32]) torch.Size([1568, 32])\n",
    "#             torch.Size([1, 1568, 32]) \n",
    "#             Throws the following error:\n",
    "#                 The size of tensor a (1358) must match the size of tensor b (1568) at non-singleton dimension 0\n",
    "            print('rejected:', b.size())\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        optimizer = optim.SGD(model_to_optim.parameters(), lr=lr)\n",
    "        #optimizer = optim.Adam(model_to_optim.parameters(), lr=lr)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model.reset()\n",
    "#         a, b, l = torch.Tensor(a), torch.Tensor(b), torch.Tensor(l) #already Tensor objects\n",
    "        out = model(a.squeeze(), a_m.squeeze(), b.squeeze(), b_m.squeeze())\n",
    "        loss = criterion(out, l.squeeze())\n",
    "        \n",
    "        los_val = loss.item()\n",
    "        losses.append((lr, los_val))\n",
    "        if los_val > 5:\n",
    "            break\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lr *= 1.05\n",
    "    losses = np.array(losses)\n",
    "    #plot_loss(losses)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_LM = torch.load(\"oa_language_model_lr001_e20_v2.pt\")\n",
    "\n",
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.4\n",
    "\n",
    "WIKI_encoder = MultiBatchRNN(bptt, max_seq, vocab_size, em_sz, nh, nl, pad_tok, dropouti=dps[0], wdrop=dps[2], dropoute=dps[3], dropouth=dps[4])\n",
    "\n",
    "WIKI_LM[0].state_dict()\n",
    "WIKI_encoder.load_state_dict(WIKI_LM[0].state_dict()) #SNLI_LM[0].state_dict()\n",
    "\n",
    "#2 pooled vectors, of 3 times the embedding size\n",
    "siamese_model = SiameseClassifier(WIKI_encoder, LinearClassifier(layers=[em_sz*3*4, nh, 32], dropout=0.4)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected: torch.Size([1, 2734, 32])\n",
      "rejected: torch.Size([1, 1988, 32])\n",
      "rejected: torch.Size([1, 4200, 32])\n",
      "rejected: torch.Size([1, 4200, 32])\n",
      "rejected: torch.Size([1, 1568, 32])\n",
      "rejected: torch.Size([1, 2138, 32])\n",
      "rejected: torch.Size([1, 2138, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd4XNW18OHfnj7qXbLl3uTeKwZjirEJoSaXACkkISGFhHAh5SZfclNIQgrkJiSkEAKEEgOhmRK6MeCGcceyZVuWLVlW7xpp+uzvjzMzkmzJlozKjL3e59EjeTRl+2hmzZp11t5baa0RQggRP0xDPQAhhBB9I4FbCCHijARuIYSIMxK4hRAizkjgFkKIOCOBWwgh4owEbiGEiDMSuIUQIs5I4BZCiDgjgVsIIeKMZSDuNCsrS48ZM2Yg7loIIc5I27Ztq9NaZ/fmugMSuMeMGcPWrVsH4q6FEOKMpJQq7e11pVQihBBxRgK3EELEGQncQggRZyRwCyFEnJHALYQQcUYCtxBCxBkJ3EII0Q8KK5pZt79mUB5LArcQQvSDxzaX8e1/7x6Ux5LALYQQ/SAU0pgHKaJK4BZCiH4Q1BqzUoPyWAMy5V0IIc42K6vu50v+TcD2AX8sybiFEKIfpPhrSdMtg/JYEriFEKIf2EPtuJVzUB5LArcQQvQDe1ACtxBCxBUj404YlMeSwC2EEP1ASiVCCBFnHKF2PCbJuIUQIm4MZuDuVR+3UuoI0AoEgYDWev5ADkoIIeKK1ji1G69pcEolfZmAc4HWum7ARiKEEPHK78ZESEolQggRN3wu41uMBW4NvK6U2qaUunkgBySEEHHH22p8M8dQjRtYqrWuUErlAG8opYq01u92vkI4oN8MMGrUqH4ephBCxLBYzLi11hXh7zXAc8DCbq5zv9Z6vtZ6fnZ2dv+OUgghYpk3HLgHKeM+ZeBWSiUqpZIjPwOXAHsGemBCCBE3Ihm3OXFQHq43pZJc4DllrDNrAf6ltX51QEclhBDxJFzj9sdKjVtrXQLMGoSxCCFEfBrkjFvaAYUQ4qMK17gDlhipcQshhDgFnwRuIYSIL95WPNjAZB2Uh5PALYQQH5XPRTtO2eVdCCHihtdFG07MpsEJqRK4hRDio/K5aMMhGbcQQsSNSMZtzHcZcBK4hRDio/K10qYdUioRQoi44XXh0lIqEUKI+OFz4cKJySSlEiGEiA+RjFtq3EIIEQdCIfC30aodWCTjFkKIOBCe7u7SDimVCCFEXAgHbmkHFEKIeOHtyLjNZgncQggR+3zGJgptyMlJIYSID95OpRKpcQshRBzodHJSArcQQsQDybiFECLOhGvcLu3AJDVuIYSIA5JxCyFEnPG50CjasUvgFkKIuOBtRduSACXtgEIIERe8LkLWRADJuIUQIi74WglZkwAJ3EIIER+8LoKScQshRBzxdQRuaQcUQoh44HURlFKJEELEEV8rQYuRcctGCkIIEQ+8LgKRUokEbiGEiAM+F4Fwxi193EIIEesCPgj6CJgTAKlxCyFE7Asv6RrNuCVwCyFEjPMaKwP6o4F7cB5WArcQQpyucMbtN0sftxBCxIfwkq6+cI3bYhqckNrrR1FKmZVSO5RSLw3kgIQQIm6EN1GIBO5Bitt9yri/BewbqIEIIUTcCWfc/lg8OamUGgFcBjwwsMMRQog4Eq5xe02RUkkMBW7g98B3gdAAjkUIIeJLpMYdDtwxc3JSKfVxoEZrve0U17tZKbVVKbW1tra23wYohBAxK1zjjmTcsVQqWQpcoZQ6AjwBXKiUeuz4K2mt79daz9daz8/Ozu7nYQohRAzyusBkxW+yAjEUuLXW39daj9BajwGuA9ZqrT8z4CMTQohY53OBPYlgSAMxFLiFEEL0wOsCW3JH4B6kGrelL1fWWq8D1g3ISIQQIt6EM+6QNgK3LOsqhBCxztsKtiQCQSNwx1o7oBBCiONJxi2EEHHG0wL2lEGvcUvgFmIIrdl5jAPVrUM9DHG6vC3gSCEgXSVCnB201nzvmd08uP7wUA9FnK5wxh2SwC1i1b/eL2NtUfVQD+OM0eoN4PGHqGn1DvVQxOkI+iHgBkcqQS2lEnGarv3rJn77WtGA3LfWmt++VsQD70l22F9qwwG7ptUzxCMRp8XTYnzvlHHLyUnRJ4fr2thypIH3DtYNyP3XuXw0tvs5Utc2IPffk51Hm2h2+wf1MQdLJHDXSsY9oErr27jw7nXsr+rncwneZuN7uMY9WK2AEMeB+7kd5dz44BZu+PtmimtcJ73u0YZ2Xt1TNUgjGxpv7TNKGPurWgkE+38Rx8gJtIpmDx5/sNvrhEI6mnn0h9pWL5/4y0b++s6hfrvPWBIJ2HUuX7Qr4VRaPX4uvGcdHxxpGMihnVGe3lZOSV0bT35wtH/vuFPGHdR60LJtiNPAfbC6le/8ezeH69rYeKie1wpPHpR/tGYPt/xrO/4BCGi9UefyDnht+PW9xv17AyGO1Pd/Vty586GsoT3687Pby6lsdgNw3f2b+e4zuz/S47R4/Hz737uoaHLz5r5qgiHNzrKm6O83Hapn6a/WsqOs8SM9Tn95c281R8PH4/vPfsgPnvuw17eNBO5gSNPQ5uvVbQ7XtVFS28auo02nvrJAa82LuyoA+M+Hlf2aWOANB26HUSoZrPo2xHDgfvdALRuKT/zYr7XmR2v2kGi38NzXz2FURgKFFc093k9xTSvr9tcSDGmqmoemlnjP6we46Z9bafX07SN/s9vPDX/fzJbDJ8+uGtt8bD3SwMVTcgHYW9n9R8LfvFrEM9vK+zSGFo8frXWXwH04XC6pbfVy+1O7uOf1AxwJl2rW7DxGvavrR/8jdW3c9cq+XmWVa3ZW8PS2cv64tpjXw2/IeyqaCYU0xTUuvvLoVo41uXl0U2mf/h8DYUNxHV96ZCv3vV0MwBt7q9lcUt/r29d2Ok69rXNXtxi3aWzvXaA/2+051sKR+naWTsikqsXD1tJ+fMPvlHGf1aUSrY2P2oFgiNuf2sXPX+66U9rOo018/qEP2FzSwHdXFZCZZGd6fgp7jrX0eJ8PbjgS/bm80R39+a7/7OO/n9yJ1icGkzpX/9UcA8EQrxdWoXVHwOutP751kI2H6qMBrCfPbC8npOGr54/DYlIUVZ54PPZXtfLndYe4+/X9vf5Y/nphFfPvfJP73y3hQLWLyXnJgFEzBCiqMh7nlQ8reXbHMQD8Qc2z2491uZ+HNx7hb++UsK0XL5oXdxrZ0TPbytlQXE92sp1WT4DShna+/e9dWM0mLpycw6uFVbT7Aqe8P5c30Ov/b0+0PjEjdnkDfPdp49PF7vJmalo91Lm8VDZ5un1Odadzbbu3nSVVLUaAb2jrXRLw0u6KkyY2Z7oXd1dgNSt+88lZ2C0mXtpd0eX3b+2rZlvpaZadjsu4z8pSSbPbz85fraDib1dT+6+v8EXPP1lW9ySB7f+Cg2/QcHAzt/9tDcXl1Xx3VQHXLxgFwLThqZQ1tHd7AutAdSvPbi9n0dgMAI41dQTuF3ZV8NyOY7y5r6bLbR7bXMqCX7zJodru6+blje189dFt0ey93Rc46Qt1y5EG6sMv+p7uszvFNS4e3ngEgKKeTqoEfLywbhNPv/IaN4xqZm5yM1OybezrJnA/8F4JAJXNHjYd6j4r9PiD0f/Lm3ur+frj2/GHQjy88QhlVXVcnX2MTzm3krV/NWx9kMCOJ1hs2kuW/xgPrtvHzBGpzB2VxhMflHU5Juv2G8d4bVHNCY/55AdllNUbpYbK6hpsZe/wl1Fr+ZXpTzxs+hmvOn7I87YfYX78Gq6q/D2/m7SHW+fZafcFT1kic3kDLPvN26eske8ub+KaP2/o8RPRa4XVLPzFm3xY3hw9Trc9sYPKZjfnTsjiQHVrtJzj9gdpcZ/6DQWMwJ2eYI3+3BvV4eddYy9KK6X1bdy6egd3PLWLUEijtcYXOLs2sXrvYB2LxmaSn+bkvInZvHOg6yYv/7umkD+uLT69O49k3I40gloPWg839HF1wIGUYjdj1gHaqw+RU7eLL5ubsaogvPAoABnAWgvG5mkbEqBwFKSN5kqVS4M5ROXmFlKnzID00WBP5sPyZj774PukOKz84uoZXPy7dzgWzrhrW71Uhl8Ad760l/MmZuGwmilvbOeu/+xDa9he2sj47KQTxvnm3mpeLayizRfgs4tH841/7WDphEx+cfUMhqc58QaClDe6o7d9dU8VDqsJf1BTUtt9xr3+YB2PbS7ljzfMwWo23kv/uPYgTquZhWMz2FVuBIXauhqK3nmapKNvM1MVY2o8zBVorrABNcAfYQ0myptzYfVcyJ0K+fOoTZ3Gmp0VXDt/BK/sqWL1ljJWf1BGIBjib5+dDxgnFq/+80YyE2384RMFPPL009yRXsalGVW4S7cxSZVjPhgOxseMrwuAC2zGRSGtaGkbiSt1Ek83plD8TgUTZyziSDCbI/XtmBS8XVTD/1w62biBr43t2zaz9aVXyc+sYJTjMHk1e3nMpqEGGu3ZlAUzScsdSWFzDZaGWj5h3kXyvtdh3094MWEym9/9GEy9A+wn/p3AmJXY0Obj7aIabrlgQo/PvRd2VrC9rImtpY1cUJBzwu83l9QTCGnufn0/9316Ljc/spWNh+q588ppZCXZWV9cx3M7Oj5lVDS7SQ0H5JOpbfUydXgKG4rrex+4wxl3b0olf32nhJA23vjX7DrGY5vLMCvFk19ZjBrEeuxQcvsCZOQYz4+8VHuX7NrjD1LR7CYzyXZ6dx7JuO3JBEODt20ZxFDgViYTti++wKX3ricY0swekUpJeQX/d/lIFuaE+P6jb7NkuOLT0xPAVQNNZdBYyvDGDfzI6oJ3HoN3wneWkIXNl8lvyGHRrLmklleyMrGethorBMew55iROd160UTufesgl937HlfNzufVwio04LSaKaxo4XJ/kO8+vZuvLR/PlGEpAOytaCZReThw8AC/Lt7FxelQXXKYz/9mByNzMihsslPlMfPs189h9og0Xt1TxfJJORRVtfSYcT/+fimvFlbxxt5qPjZjGKGQ5r2DdVwyLY/5mV7yDv4H70N/Iq10PecRoFansCNhOocSFnHAm8a3L1+A02YFbws7du2k6tAuhtUWYz3wKugg2cDblizS3ItZkZvLy4V2GknGp2x49zdhb6/m8MFCvlS3iyn1R0n9QzmPEIQ20DqLTeZR/Mk/n1UXr+L5Mjsbyv288M1lfPnv6xjnaGFOajv79u3m5uEehjcWcaulBNO6Z2EdjDA5WGtLw5qUQWVjEN+f7di8jdB8lLnAXCu0NCfgTV/EattMShzT+NnXP0eCJYnRviDmBBv3/Gk9u8qbmTsylWc/mQEHX2f4hof4cuPvCN39N0xzPg1LbiGQMoqQBpvFePNbvaUMgF3lTbh9QZw2M1prXiusZnlBNg6rGTA+FQHsOtoUDdybDtWzrbSBb1w4kZKj5Sw1FZJ/qIpn7vkHF7pb+Om0HCZ6P6Q+mMtiUx2F++ox0gtFVbMn+nw5mVqXl5kjUkl2NFPT0rsad1UvA3dVs4dntpVz/cKRbC5p4PandhH5ELSttJH5YzJ69XjHc/uCXP3nDeSmOPjcktFcFD6vEqt8gVD0+ZBgs9Du6+iIKq1vR2t6fWL4BJ5msCaA2UowFBrUGnfMBG6AyXkpfG7JaB7acIRvr5zMjQ+1sN2VTpHPwku+Odxy5Xlw3AvCpDUr71rDJcPc3LHADk2luGsOUbNjB4sSS0jdthG2BvkbwAHgTlhiTmatLYnRpaP4zPhkdlf7qX3bxOftCcybkM7ByiZM+wI01Vu5pqQM22EvJPnA3cRd7iZ+Y+/0cbMdMIe/wif66+ypeJ4cQX3ORK5ud7I853ye8aayp+bEylQwpNkYLl08sukIH5uaTemH67ne8xRfrDxAxt5dKKumqWYkTwRWMWbpp2hIn8kPni8E4O7/moVz9ojo/flSLuWWos2YKuHaWVnctSTEfY89yTxLCfn1H7Ki6SVWdE4wVhvfxqJINGfSlDiWvzbPJnvSYj515RWolHy2v13MfW8Vc+PCi3AGS9m99wCt1kzeqU9l3LmzuGDFJIZXtZI4Ig2A3760gw2b1vPQxxJ5f/N6bO5qFmeYONpaR1Grg4bQBI4lLOfdpiyWLFnKTzd4KGhOpaillfuvnAeOVOyA3WIE1un5qewqb+ayWfmQOxZyp9JS8CVu/t39/DJvGwVbH4IPHmCr4zzubltFxoSFTBueyp5jLVw4OYe1RTVsL2tk6YQsCita+Opj27jlgvF8Z+VkXN4AhRVG5hTp1NChIKuffYaC5vfwFx7gkfoiiBwzHwRsCVjKgENuMtE8Ef5dky2VbYFxZGxdAo7LYMQCsNi7/L1rWjx8+ZGt/O/l02ho85GdbCcn2d7rGnd1L2rcWmvufHkvQa35+vIJLBrbyG1P7uT7l07mvreLeXjjkVMG7sN1bbx3sJbPLRnT5fKiqhaKqlo51ujmnQO1vP3t5YzNSuzV2IeCL6ijgdtpNeMNhAiGjLLG4TojkfpIgdtuxKNgaPCmu0OMBW6A762azAUFOZw7MYuxWYnsr2qlpLaNRWMzus9ilGJk/gheqGnlloJlOKxmXttxjNu27GTNp5cya3gStJRz7zNv4K0p4TvnpLFxWyEmdz3jLIqc9gouSmpD2z2Ygh6ogNyAos2vsFQ6SVMOyt1JZI4sIHlsFn/bUs/kMflcMHMCypEC9mQIBY2pr34PtFZSuGUrie3HmHB0A9+31sKm1SwBmnUi+sGZqOzJkDIc7ClUNnv4tG8vk9PcpB09TPDXRxjra+U7VvBZZuBZ+j2uXJtOrRpLSyjI1mUXk5ZgpajaRUWTh2vm5Hc5HIvHZfDEzYt5Zls5T2wrJydjAve2ruCe/5oF80aA341uOkpDXTXfeHQTnz1nPBPHT+Bj/zzCty+dzmeXjCZjRwWXzxkONuPp8bXlE7hiVj5pCTbGhF+kb++vxRcMMSUvBbvFzMxw0Aa44dzJ/HVjJZ/Zlsz++jw+u2Q0F3x8Kj/83TuU1LYxe2QaIa0ZPTKRGz8+mxfLN7GttJGLp+RwybS8E/7E507I4rkdx7hsxrDoZWOzkwiNXMS3PPN59bbf4n7vPqZu+QdPm95h6+EZPFB0ESnWBfz8qumc++u1bC6pZ+mErOinngfXH+HGc8ZQVNlKMKQZm2om+eha9AuP4d/7H+711BIwmyjzzuZp/7Wce/4l5I6biT8hm8nDw0Ev4IOWcu5a/TptFUV8angdI6u3M7H4L1D8Z7A4YdRi9NhlNOYtIWP8Qn772n52lTfz93dLCIZ0OHA7+hC4jes1tfvQWndb8vjLO4d4eXcl311VwMiMBEZmJLB0QhbZyXZqW708vPEI1S0eclMcPT7O3a/t5+UPK7loSi75ac7o5ZHuoge/sIDr79/M6i1l/OBjU3o19qHgCwSxhcuPiXYjEXD7gyTZLZSEmwXafUE8/mD0E1ivhReYAghpjWkQzxjGXOB2WM0sm2RsNlyQl8ybe6vxBkLcvGxcj7e5ZFoub+6rZuXv3+X3n5rNuwdqyUi0MSM/FUwK0sfQNvxcHjo8gjuWreL7G99i6cQsln9qNgAq/BXx6rZy7vj3LpKwUDAsmQNVrZxnyuKWeRP4zYb13Dt/DmrW8B7Hc8xexg+e+xCrWXHd9GTuXGJi65b1FO1+nyvdTZh2PkNi0MjyRgDftUIomMheUw6bncv5MHUWr7RNZM0tVwHQ8sFbNLZ4WDQ2g/REI7372ZXTu31spRSLx2Uyd1Q6m0rquXdtMQk2M6umhwOi1YnKnkRG1kSKE7282Z7Fxv0mTBYb1y0YRYLNwg2LRnW5T7NJMSrT2MV61ohULCbFz140Mv7Jw5JPGEN+mpOPzxzGy7sruWpOPt+8cCJKKR67aRGBoI7eV8SXzh1LaX0bP758Wrf/p1XT87hgcs4JL6xr5o7gR8/vYa8riX15X+Mn3tm8vuww84oeZr7+PQF7Gpa3L+XWzGGU7W+B8/MprW/HRIjUYBMvPb+aAm8hj9o2szhQjDXkJvRhIrus81ijrmerfT4ljTZ8wRCfnHM+444/52GxQcY4TOOX89jRkZx7/jx++mIhF46x84s5zXD4XfThd1Fv/ZQMoN2UyIX+qWjLfNbtmwMkkZ1kJyfFzo6y7vuy/7T2IDNGpHH+pGw8/iDNbj/pCVYa2/20egOkOLrW0ssb2/nta/v5+MxhfG1+KhxaC83HyPY0gcnCV9Oc7NZ1vLhlGF+6eA4NbT4SbOYux7ap3ccb4XkBWw7Xc/Wcjk90+6tcOKwm5o1KZ8XUXP699Sh3XDIp+ukowh8MUe/ykZfa85vDYPB3zrjDiUi7L0CS3cLhTuec6tt8Xd6geiW8wBQQbgccvMgdc4G7s8m5yby8uxKb2cSlnbKt4107fyT5aU6+98xuvvjwB2jg/EnZXdpz8tOd+IIh9la2UN3iZXp+ao/3F/mdyxvg0ul5LB6XwZ/XHWJYqvGHnTb85PXLFVNz+X/Pf4g/qLl04RQYk0VIT+GH26dzb5OdmjYvVgIsHWnH7fXhMyfw3Lcu5o03DvCHtw5iUvCpBR3Bc/KwZKpaPKyY2vt6os1i4o5LJvHfT+5i1fQ8Eu1d/9RKKWbmp7K9tJHGdj8rp+X16oTa6MxEfn7VdP7nWeONaVxW9ycGf/2Jmfzk8mnRNxqA4T28MC6dMeykf1+lVLfZ0OUzh3Hni3v5+3sl+AIhnMnp5K76JGrVHVD8FpY9z8D+V7jN0wQu4K6v8g0UtzrCxd5DxknVUusYWgqu5fadeYyasZJHP6ji1osmstjtp2jjEZIdFsZk9lwOOH9SNo9vLmXuqDTyUh0caTPD5Mtg8mXc/uRO3ivby43Dy8iq2cxFlp1cygcEtImtuoDhZZ+k2DaH11pPzKA9/iD/9+ZBUp1W3rr9/Gjn1JRhKWw8VE9jm69r4Naa3Vve5gfmx7ix5gDq7hO7JbKAp+wQWv9zQgemsK5uBJ7hS7jh+hshMRMwOq58wRBWs+L9koYugftAdSuTcpMxmRQ3LBrFK3uqeHl3JdfMHdHlcZ7YUsavXili249W9D2T7UeR/wdAQngc7nCdu3N7buPpBG5vCziMWBEKaQaxUhLbgbsg3Dd8weRsUp0nDypLJ2Tx6E2LuOq+DTS7/ZwfztojIn+Up7Ya015njug5cI/PTsRuMeENhFhekE1Wkp1HNpXyj/WHcVrNJ30RA2Qn21kwOoNjTW4Wj82M3icY/brfWVlAeoKNu1/fT0Obma+ebzzpb71oIlsON7CppJ5zxmdG72/KsBTW7a/lkqknlhFO5spZ+RxtcHN5D58OZoxI5a1wi941c/O7vU53rls4iuoWL8ea2qPZzPEcVvOAv2DTEmzcvGwcf3q7GJvZxNVz8sNv1maYdInxFQqy8f1NPPniy3xnSTIb95VhMpm5+rzZvFBm4yc7Ernx3Jl888IJbNr9Gu98UEVBbjI3nTuWD8ubeXjjEWbkp560R3fxuEx2/2QlAMNTndF2zH2VLTy34xhfXz6Xb666gZ1Hm6hRGlNbEasf/SuXmLYy6oM7+SZwnhqH9919OGZeA+ljAKN9NDKr8levFHF1+G80Oc8I3A1tPkZnJkLtASh8FnY/xccaDuGzWLBmng8LboRhs4z7c6YZJT13I/95ZwNF297hGt8xLg6+R0r56+jf/gw1fDaMv5B9u3OYkTeJ3PRk3j9u8tf+6tboa2vp+Cwm5Sbxg+c+RGv4xLyO4H2kvp02X5DGdl804SmucdHs9jNvdPpH+ruX1bfz85f3sr+6ldf/e9kJ2X5EMKQJhjQ2s/H7BJvxvb1T4J6Yk8TBGle0ZbdPPC2QOjL6WGd1jbuz2aPSSHVa+czi0b26/tisRP7ymbn87vUDXDi5a1tXfrrx5Hl0cymT85KZM6rnJ4/FbGLq8BSqmz2Mz05CKcVXlo3j7tcPMGVYcq/+QL+/bjbeQCj6gs9ItJGRaCM7yc7Ny8ZhNZu4dHoeqz8o45PhbMVsUtx7/Rwe2nCYi6Z0jP+LS8cya0TaCSWGUzGZFLdeNLHH30fevLKT7Zw7IatP9/2ti3u+38H0jQsn8NLuCo7Ut3PhlBNb+TCZmTBtPmvWNDMjbQp/8R7ikmm5fHLRTK5eBOdd6iXFYcVqNj7+H2ty8+hNC0l1Wlk4NoOcZHuXN9FTyUt1sLaoBq01j20uxW4xRct8s0dGzgMs4ZXsAPdUXsveb03k8HurMe15DsfbP4W3fwrDZsPES2gITCaFIAunjOXJrUejn4im5diYqw6Q9v4mePFNqN2HRhEafS4/rrsYx8yr+OEnz+l+gAkZTD9/GF/fksmfqsFpUUwMHOSeufWMb3kfvf733KWD+MwJVFrm80DjOOpLc8gcNYWGdj+1rd7oRCyTSfH4lxbzjX9t545/72LKsBSmhj+NRk74Nbb5o4H75y/vpay+nbXfXt7r43k8jz/Ilfetp7Hd+PTR7PaTk9x94I4scdFRKukI3M3tfurbfFwyLZeDNS4a2k5j0l2nGncgpDFLqcSQk+xg5/+u6FPP6TnjszjnaycGoUjGrTX8+PJppwy+P7tiOt5AMPrYX1g6lsffL2Ph2N69iI8vCyileODG+eQk26O92umJNr6+vGt/cXayne+umnzCZdEadT+akZ+GScFVs4djMcfMXKw+cVjN3HPtLO57+xDnTez+zScnxcHwVAfri+uoj2SpYVlJHV0ff/vcPExKkRQuK9ksJtZ9Z3mPGV13hqU6cPuDHGty8/yOY3x85nDSEk7sE75mbj7eLUEShk1ixMd/wPKiJZyb1ca9M8tQRS/Ce3dzng6x2wGh6ixK7A5C78MX7O3kvdLIJ+waXahg9Dnsnf1DvrA5jwJdwLu+Wh6YOv6kYxyVmRCdcXzHyin8/k0z94Vy+d1NP2Nb0WH+/sg/+fHUavKq3+NO67vw0MOQNhpf9jmsNOUxJb3jZGR2sp1ffWImF9y9jj0VzdHAHZl93NSpbbGwogWPr/sFynqrpLaNxnY/yyZl8+6BWjy+nicUecOTjaKlknCN2+0LcjikxKLhAAAeW0lEQVQ8+3fe6AxWbzna65moXXSqcYe0ZjBfQjEduIF+myiQ7LAyLNXB3NHpLOlFBjXjuFJKot3CW3ec36cX8fHmniTLHwrZyXae+sqS6IstXs0bncGDnz95e9vsUWm8VmiccBvTwyeX40/0QceLvbci2eWdL+2lzRfkM4tHdXu9m84dy5fOMzLx1AQrt6+YxI/WFHLZsmtZ9aVvgbuJ3z30OOktRXxhiplAyWEO17XhNSWw6pwFfHNdiPMvuozPXDSfNa/so5oSqg/UYjObOGfCqZ/f184fSW1rMdcuGMneyhZe21OFNxDksMvCa6EFfH/VcszpTi796SNcl1nMZ7OLyTy0hr/Z2tHP3As7L4TZ10PBZYxMd2I1qy4TzKIZdzgzrmn1RCcZnVYHR1ikK2j2iFTePVCLu4eVKgF87ja+bl7D3LL3wX17p1JJgFqX0VY5a0QqZpPqe8bdaRMFCJdKzsYJOIPhhW+ce8pa+cn09UUcD053Ika8mTUijf98aEyRHzOAfcfD0owuitcKq7li1vBO5ZGujk9Irl84isc2l3Hr6p188dxmbrt4Is+0TGH+mHPg8jmkt3i44tdvMyLVyZUrzmftuleYFDBODBcea2HqsBRmj0rDbjH16nn6uSVj+Ozi0SilWDktj6e3lbOjrImjDcYs1+FpTixmE9etWs6PX8hmffpV1Kd/jZS6nTx0TgN8+G94+otgT8Uy81qWps6mpLajVBUJ3A3hjHtfp4XPGtp8PZ6oPpXiGhdKEW0N7jFw1xWT9vh1fNd6EA4Cf3iY1Cv/Hb1N5E1kWJqT9ARb33u5o9PdwycnB3lZ1zMvEp1EdrL91FcSZ6RZnQLoqIy+nSvoi8l5yVxQkM3KaXl8asHIXn9itJhNPHrTQn796n7++s4hXF4/x5rc3JBrZOy5KQ5uWzGRYNDoPElPsNLQZqzcuKeimUun5/HLq2f0aayRsUXOdeyvaqWsoZ1hqc5oXfjGc8bQ5gvwm1f3k2S38OlFl6BWTIGL/hcOvws7/wXb/8nDwb+zrXQWFH0PPXFl9GRfU/j73oqO9XPqXacfuA/VuhiR7oyWn9zdlV6Cfnjmi5jcdXzG932+sGIeF225mZzNvwRupt1nrCdjUpBoM5OZeBqBO7KJQqQdMDi4qwOeVYFbnL1m5KdiUsab90B+ckqwWXjoCwtP67Y5KQ7uuXZW+MSmMV2/ILejT77z+ZD0BBuNbT6ONblpavczbXjPXVKnfNxkuzGpq6qF0oZ2Rh9XSvr68gl8etFoku2WjqzSZIbxFxhfK3/JuifupuDoU/DEDejUkXxBn8uTLI+WSvZ2Wvis/iRlCa01j2wq5eKpud225x2qbWN8dlL0RGO3m3ps+D1U7qL6kr+x/oVkrsucBufdgf31/8cS01LafVNp9fhJdliNN8FE60fIuMMzJ7Ue1LVK4vOMlBB9lGi3UJCX0u3CYbHmjpUF0Yw30hJ7vPREGw3tvuiSxiebl3AqSikKcpMpqmrlaEN7t59IUp3WnksBSdnUzPoG53r/QO2lf8eXNILvW1ez2f4NVhbfCdWF7KtsYWJ4sad6V89BsrjGxY9fKGTNzmMn/C4U0pTUupiQnYTT2tEhEgppnttRbuz81HQU3vkNTLuahtGXAhgzJxd8CZ2Szx2Wf+P2BWjxBEh2GG/gmYn2vrcDRheYSomObTDbASVwi7PGH6+f0+dywlDIT3Nyy/IJjMxw9jgpJCPBRlO7j8KKZswmFW3RO11ThqWwr7KFOpePkadRShqXnUgQM3tSl7N35WpWen/Fs8HzmN3yFvzlHP6n8SdcN8w4OXyyjDuyeUp3S+Mea3LjDYQYn9MRuN3+INvKGvnvJ3fx7sFaWP9/RuvYijvxhdsBrRYTWB2ohV9mvukAJlclrR5/9GR0f2TcAQncQgyMCTlJA3pisj/detEE3vn2BT1muemJVupcPrYeaWRiTtJHnuxUkJeMx28EuuNLJb0RWQ7gUK2LBpeP/XoUv7J8lZsyHqFy7u3MMx3gpv1f5jHbXajajg1Sbn5kK9ffvzm6FV1kwbXu1kaPdJSMz07CYTNCl7H+uXHd+oojsONRmPMZSBsZXXvcHunTm2Rk4CNr3+uScWck2ml2+/u2V+vxGfcgr8ctgVuIGKSUOmmXQm6Kg4Y2H5tK6k86C7i3Omfsp3PyNiPRRlqClZK6tmj2Oj4niaMeOxvzb2Kp917qzvkRM02H+eKHn4M3f0JVQwuv761my5EGrvnLRt4uqolu/dbqOTHjPhRuNxyfnRjNuD2+IC6vcd2xRfeDDsF5twMdE3Cskdm92QUcI4fxTetpcRs1boDMRBtaQ1M3m7H0yB1eW2aI2gElcAsRh7503jju/+w87r1+Dt9ZOfnUNziFSbkfLXADjMtK5FCn6eMTspNobPNRWt+GRzlIufB2vpJ+PxsSV8D6/8P+8ApGqBqe+spixmYm8q0ndtASDtg9ZdypTisZibYupZJ2X5AcGplVuwZm3wBpRidOJOOOrA6IUrxvXcAE11Z87jZSnEbGHVlPp0/lEncjoMBhdCsFz9aty4QQvZdkt3DJtDyumDW8X9pcE+0WRmcmkOywnPZch8nDUthb2UJtqxeH1cTwNCctngCHatsYkZ6AzWLClpzN3c5vwnWrsbnKecn+I+bqffz0ymnRoD0xJymacTe2+WgLZ9TVzR7y05wopbCYTdjMJtz+IG3eAF+zvIBJB+G8O6LjOX7KO8A2+2Js2scU745ojTszHLhPdtL0BO5GY/2X8DT34Nm8WbAQYugsGJPBzBGppz1becGYdFo9ATaV1JOZaI/up7nzaFP03EJmoo16lw/fhFX8V/AX+OzpqMc+wXnmQq6Zk8/CMRmMzUqMlj8+/9AWfv7yXgDq2nxdthlzWE24fUF0azXXm9fysjo/ukAXdJ7y3hHmDiXMxKvszAnsJiVc444E8Mhj9oq7AZwdM6GDgzwBRwK3EAKAX149gwc/v+C0b78gPAt3X2ULmUm2aAniWJObseETnplJNurbvGwtbWCvN5u9lzwBGWPhX5/innkNPPmVxSQ7rNGMu7ShPTqVvt7ljWbHYCwa5fEHmXvkAcyEuNtzRZe+7ujJyU4Zt9Xu5IBpHLNMh6I1bmf4RGe7ry+BuxGcHbOOQ1LjFkIMBZvF9JHW4slPczIsvHGCcbKyI8hGFvbKTLLj8Yd4cVcFNrOJ+dML4MaXIHMCavV1qOK3SHZYaPH4CYY0zW5/dMGqhjYfmZ0WBXNazTjbyplV+zxPBZdTpnM51uSO/t4f1NH/V0SCzcyOwDimqyOk2IzfRzZY6HYyT0/cjV0y7oCUSoQQ8UgpFc26MxJt0VIJEN2XMiOcMT+/o4Jlk7KMlRgTM+HGFyG7AJ64gRmerbi8gfD2bFDb6sXtM05Cdi2VmLmk5kFCmLg3cDUAxxo7ArcvYATizqWSRJuFD/xjcSofw/2lAF0m8/TacYE7FGsnJ5VSDqXUFqXULqVUoVLqp4MxMCFE/Fkw1gjcmYk20jtl3JEad1Y48Lr9QS6d3mnXo4QM+NwayJrElUXfYbEqjGbPLZ4Alc3u6P1GLGI3S1xv8GbqJ3A7jAWuyjsH7m5OTjptZnZqY9nbvFZj+73IqoEnW2nwBO2NxpjDgjr2SiVe4EKt9SxgNrBKKbV4YIclhIhHC8MZd2aSsf4JGBuEjAhvZJKZaJQ6rGbFxVOO24ovIQM+9zyuhJH8w3o3rfvfif5qf1Vrl9vjbeUbrfdyzJzPU4nXMzY7CbNJcaypPXqbaKnE3LVUclTn0KCTyGjaDXTUwHu9VngwYCwy1fnkZKxl3NrgCv/TGv7SAzoqIURcmpSbxP9+fCpXzh5Okt2CxaTC63UboSZS6jhnfFb3e5wmZvHBsoep0Jks3HAzl5reB6AoHLgzkmzg98C/v0BmsIb/S7iNJp+FFIeFvBRHl1LJ8RspQKSerdgVGk9ynRG4lVI4rebel0o84ZUBjwvcMVfjVkqZlVI7gRrgDa31+wM7LCFEPFJK8cVzxzIs1ei3TkuwdVlmICfZwYz8VD63pOftCO1peVzv+yEVjgn8xfYHfml5gJqjxsbHed4jsPo6KH6D1Tm3s51JtHmNXdvz051dTk76AiFsZlOX9sZIWWSXHo+1YT94XdHLe1sq0e3G7M7jA3fM7TmptQ4Cs5VSacBzSqnpWus9na+jlLoZuBlg1Kjud/0QQpxdbr1oQpeZmDaLiRe/ee5Jb5PksFBLGj9MvYsLWu7jM+Y3uKFsLT+wO0l+3A0WB1zxR3YemoWnuA6lFAk2Cwk2C+8drI3ej7/TDu8RkcC9NzQahYbaIhgxH4fV3P3a3sfRWnPLP97iz9C1HVAzqMu69mlhYq11k1JqHbAK2HPc7+4H7geYP3++lFKEEHxuyZg+3yYyMaakMcCm0I08EPgYV1vWk21q5caLFqDmfR4SM3Ee3YPbH0QDiXYz+WlOntleTlO7j7QEm5FxW7oWFSIdJCWmcMZfsxdGzO91xh0Madwt9WDjuHbAEBZzDJVKlFLZ4UwbpZQTuBgoGuiBCSHOTpGJMZXNbjISbbQ5h3Ff4Cr+nnAzatkdRvsgRhCOTHk31ls31luJ1MO7C9yRTTSa7cPB4oQaY6VCZy8DdyCkScMorxzzdvSUh0KDm3H3psY9DHhbKbUb+ACjxv3SwA5LCHG2iiy3GtJG33dkLZaMTq2AYPRxe/wh/EFNos3M5DxjidVIB4pRKjk+cBsZd5LTDjmTjYwben1yMhDSpCsjcL9a0rGueHCQd3nvTVfJbq31HK31TK31dK31zwZjYEKIs5PTao6e6EtLsEZ7vztPvgGi25eBsUhWboqdVKc1mnF7g92USsK3SXFYIGdql4y7NzMnA8EQqcpFSCue22sEcK21LOsqhDi7KaWiWXd6go3sZGMafbSHO8zZafOIRJvF2IItL5n9VcYmB/5wV0lnkYw72WE1ArerGtrq+5Rxp+GiVSWyp9JFnctLKHxGz2wavHAqgVsIEXOigTvRRnZ4fZITMm5r14wbjA0hDlS70Frj6ybj7gjcFsiZYlxYu8+ocfcmcAeNUonbYpRlalq8BMORO6ZKJUIIMdiS7eH9IBOs0Rp35vE17k6lkgS78XNBXjIub4DyRne0j7uzyIJSKZGMG6BmH05rL0sloRBpuPBZjZ1vGtp8hLQRuGNq5qQQQgy2zqWSSI37+JOTnTPupE4ZNxgnKP3dZdzWThl3cp6xg011IQm2rqWSkloXP3z+w+hmDBHBkCZVtRGwGzvf1Ld5CYQz7pibOSmEEIMp0hJo1LiNjDsrqecad6QEMjG8BVtxrQtfoJuuErsZm9lEVrIdlDLKJbX7o62FOpw9v3uglsc2l7G7vLnL7f1Bo8atwz3c9S5ftFQSa+2AQggxqFKiNW4ri8dlctvFE1kyPrPLdbp0lXQqgdgsJpra/Xi76eO2W8w89dUlfHpReHZ31iSoLYqWXSI73UfWOdle2tjl9sFwO6ApIQOTCpdKojVuCdxCiLNYUqdSicNq5raLJ+Gwdt3kobuTk2AE72a33yiVdHPGcPbItGhGT/ZkcDeQro3MOjIJJxK4tx0XuP1+LymqnaA9nYxEG/VtPimVCCEEdK1x96RrH3fHz6lOYwed7rpKTpA9CYBcr7GpQmT7Mm94E4atpY3R8gmAaqsDIJCQTUaijYY2r5ycFEIIMOrZZpMylnHtQSTjVqpr9p3itNLi9nfbVXLiAxUAkOkxAneksyRSMqlzeTna0LHioKmtCugI3J1r3IM5AadPi0wJIcRguHb+SGaOSI3uwN6dSLCOTL6JSHVaaWzz4Q9qrJZTBNPUEWBNJK3tMDAJty9S4+7oMNlW1sCo8GbHprYaAEIJuWQm2dlX0dJxclIybiHE2SzRbmHe6IyTXscR3p29c5kEOmrcRsZ9is2PlYKsiaS4SoBOpRJ/iNwUO0l2C1uPdNS5zeHAHUzIJjNc4w5KjVsIIXrHZjZhUh0dJRGpTistnkC3qwN2K7uAxJZDQNeTkwk2C+OyE7tszmBuN9b71km5ZCTajDeIcK+3dJUIIcQpRLYc69xRApDitEQDqq03a2RnTcLWVkEi7ui0d28giN1iOmENE6u7hgadhNlqj87krG01VgmUPm4hhOgFp80cnXwTkeq0RssXvc24Acarii4Zt91iOmHVQKu7llqdhsWsyAxPCIoEbimVCCFELzi6y7g7ndDsVeAOd5ZMUMeigdvjD2K3mE+YCm9z11Cj07CYTNEp+NGMWwK3EEKc2rzR6cwemdblslRnR+A+fsp7tzLGok0WJpgqOpVKQtitJpxWS5dVA+3uWmoJZ9zhwP3+4QbgxCn5A0naAYUQcesP18054bIUZx8zbrMVMsYzofoY+yOB2x8iM9GM02bq2NJMa+zeOmr0XCwmRVL4cd4qqiY3xc6c495ABpJk3EKIM0qfM25AZRcwwVRBu7/TyUmriQSbJdoiiKcJc8hHrU7FbFKkJdhQCrSGy2YMl1KJEEKcrs41bntvMm6A7AJGqWp8Hg/QcXIysq9lKKTBZfRw1+p0rGaTMbMzPCX/8lnD+vc/cQoSuIUQZ5TOGfcpp7xHZBVgIURiW2Tqeyh6chLAEwhCqzHdvYa0aM92RqKNEenOE+rsA01q3EKIM0pkZUHofakksthUWpsxgzLSxx0J3O2+IAnRjDsVa3h/yTsuKcBpM3eZcj8YJHALIc4oZpOx2XCrJ9C7k5MAmRMJochwHwE6ukoiS8m6fUFwhTNunY45PLFn1fS8fh9/b0ipRAhxxonUuXsduG0J1JpyyPUcMTYaDoRwdCqVuP1BcFUTMNlpxTmok226I4FbCHHGidS5e10qASpto8jzl0U3UTC6SjpKJTQdxWXLAZQEbiGE6G8pTqMK3OuuEqDSPo4RgTK8Xk/4tuaupZL6Yhqco4HBXVCqOxK4hRBnnEjG3etSCVCVUICVAMGqfQDhk5PGG4Db54P6Q9Q7RmExqUE/GXk8CdxCiDNOpMbdl1JJbdJk44fKXQBdukp0czkE3NQ5Rg15tg0SuIUQZ6DTybi9KaNxaSem6nDgtpqju+xYG431umtsI/v0ZjBQhn4EQgjRz1KiJyd7nx0nO20U6tFYaz4EwBFe1hXA3nwYgFqbZNxCCDEgJuUmk55gPemelcdLdljZExqLo34vJkLYrR3tgAmth8GeQqNK69ObwUCRCThCiDPOymm5rJy2ok8nEZPtFjaFxmAOehinKoy1SixG4E5pOwKZ4wnqoe8oAcm4hRBnIKX63vmR7LCwR48FYIY6jN1iwmRSOKwm0tpLIXMi/qDGYhr6sDn0IxBCiBiQ7LBSoofhMSWy2LQPezjbzrAGSfVVQdZEgqEQlhgolUjgFkIIjMWpgpgpTFzERebt2M3GvpVTLBXGFTInEAhpKZUIIUSsSA6vKrjRuogs1UJK/U4AVrCZICYYu4xAUEdXBhxKQz8CIYSIAZHAvTYwC582k3j4NQiFuDDwLnsc8yAxK34ybqXUSKXU20qpfUqpQqXUtwZjYEIIMZgirYOlbRY2h6biKH4FSjeQE6rlXccFAARCoZhoB+xNxh0A7tBaTwEWA7copaYO7LCEEGJw2S0mLCZFY7uPF0LnYGosgcc+gVc5eM+8EIBgvGTcWutKrfX28M+twD4gf6AHJoQQg0kpYwMGreGZ0DL0f/0TsiaxPuUyGvzG3pL+YCj+2gGVUmOAOcD7AzEYIYQYSsnhcondYkZNuwq+tp6X8281lnXFyLjjqh1QKZUEPAPcprVu6eb3NyultiqlttbW1vbnGIUQYlBETlBG1uEGSLCZjR1wAH8wTkolAEopK0bQflxr/Wx319Fa36+1nq+1np+dnd2fYxRCiEGRZD9xAwan1Uy7LwAYGXdcrA6ojHmj/wD2aa1/N/BDEkKIodG5VBLhtFnw+EOEQjp+2gGBpcBngQuVUjvDXx8b4HEJIcSgS3GcmHFHVgj0BIIEgrHRDnjK1QG11uuBoR+pEEIMsKRI4LZ2LZWAsWGw0Q4YB6USIYQ4WyRHM+7OpZKODYP9odCQ7/AOEriFECIqUuN2WE8slbj9QYJBLYFbCCFiSbcZd6dSiT/e+riFEOJM1207YKdSSTAkGykIIURMSYm2A3YulRjB3O0PEAiG4qYdUAghzgqnKpUEQjom2gElcAshRNhJT06GA7e0AwohRAzp6OPuph3Qb0zAka4SIYSIIcndzJyMlEravEFCGukqEUKIWJJkszA5L5lJucnRyyKB2+X1A8RExn3KKe9CCHG2MJkUr9627ITL7BYTLW5jhUBLPKwOKIQQZ7sEmxmXNxy4YyDjlsAthBCnkGCz0OqJnVKJBG4hhDgFh7WjVGKWUokQQsS+BJuFFsm4hRAifjhtZlo9UuMWQoi44bSaO2rc0scthBCxL8FmpjXaVTL0YXPoRyCEEDHOaTOjtfGzlEqEECIOODutXSITcIQQIg5EVggEybiFECIuOG0dq4PIRgpCCBEHupZKJHALIUTM61oqGfqwOfQjEEKIGOe0ScYthBBxpUupRGrcQggR+6RUIoQQcUZKJUIIEWc6l0qkHVAIIeJAQqc+bquUSoQQIvZ1ybilVCKEELGvc43bKqUSIYSIfZ27SqTGLYQQccAhqwMKIUR8MZsUdosRLmUCjhBCxIlIuSQuSiVKqQeVUjVKqT2DMSAhhIhFkc4Sa5yUSh4GVg3wOIQQIqZFOktiIOE+deDWWr8LNAzCWIQQImYl2CxYzQqlhj5yD33OL4QQccBpNcdEfRv6MXArpW5WSm1VSm2tra3tr7sVQoiY4LSZY2K6O/Rj4NZa36+1nq+1np+dnd1fdyuEEDEhwWaOienuIKUSIYToFafVHBM93ACWU11BKbUaWA5kKaXKgR9rrf8x0AMTQohYcn5BNilO61APA+hF4NZaXz8YAxFCiFh25ex8rpydP9TDAKRUIoQQcUcCtxBCxBkJ3EIIEWckcAshRJyRwC2EEHFGArcQQsQZCdxCCBFnJHALIUScUVrr/r9TpWqB0vA/U4HmTr8+1b+zgLp+H1T3j9VftznVdXr6fXeX9+V4xeOxOtX1Psqx6u4yOV49XzZUr8XTOVa9vV08P7dGa617t9CT1npAv4D7+/jvrYM1lv66zamu09Pvu7u8L8crHo/Vqa73UY6VHK/+e24N5PE6nWPV29udic+t7r4Go1TyYh//PZBO57F6c5tTXaen33d3eawcr4E6Vqe63kc5Vt1dJser58vi6Vj19nZn4nPrBANSKvkolFJbtdbzh3oc8UCOVd/I8eobOV69N9jHKhZPTt4/1AOII3Ks+kaOV9/I8eq9QT1WMZdxCyGEOLlYzLiFEEKchARuIYSIMxK4hRAizsRV4FZKLVdKvaeU+qtSavlQjyfWKaUSlVLblFIfH+qxxDql1JTw8+pppdTXhno8sUwpdZVS6u9KqTVKqUuGejyxTik1Tin1D6XU0/11n4MWuJVSDyqlapRSe467fJVSar9Sqlgp9T+nuBsNuAAHUD5QYx1q/XSsAL4HPDUwo4wd/XG8tNb7tNZfBa4FztgWuH46Vs9rrb8MfB741AAOd8j10/Eq0Vrf1K/jGqyuEqXUMoyg+4jWenr4MjNwAFiBEYg/AK4HzMBdx93FF4E6rXVIKZUL/E5r/elBGfwg66djNRNjGq4D47i9NDijH3z9cby01jVKqSuA/wH+pLX+12CNfzD117EK3+4e4HGt9fZBGv6g6+fj9bTW+pP9Ma5TbhbcX7TW7yqlxhx38UKgWGtdAqCUegK4Umt9F3Cyj/eNgH0gxhkL+uNYKaUuABKBqYBbKfUfrXVoQAc+RPrruaW1fgF4QSn1MnBGBu5+em4p4FfAK2dy0IZ+j1v9ZtACdw/ygaOd/l0OLOrpykqpa4CVQBrwp4EdWszp07HSWv8/AKXU5wl/UhnQ0cWevj63lgPXYCQE/xnQkcWePh0r4JvAxUCqUmqC1vqvAzm4GNTX51Ym8AtgjlLq++EA/5EMdeBW3VzWY+1Ga/0s8OzADSem9elYRa+g9cP9P5S40Nfn1jpg3UANJsb19VjdC9w7cMOJeX09XvXAV/tzAEPdVVIOjOz07xFAxRCNJdbJseobOV69J8eqb4b8eA114P4AmKiUGquUsgHXAS8M8ZhilRyrvpHj1XtyrPpmyI/XYLYDrgY2AQVKqXKl1E1a6wDwDeA1YB/wlNa6cLDGFKvkWPWNHK/ek2PVN7F6vGSRKSGEiDNDXSoRQgjRRxK4hRAizkjgFkKIOCOBWwgh4owEbiGEiDMSuIUQIs5I4BZCiDgjgVsIIeKMBG4hhIgz/x8JuCPymiWo/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 38s, sys: 51.1 s, total: 3min 29s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dev_data = SiameseDataLoader(sentence_pairs_dev, pad_tok)\n",
    "losses = find_lr(siamese_model, siamese_model, dev_data)\n",
    "plot_loss(np.array(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "             1,    1,    1,    6,    6,    6,    6,    6,    6,    6,    6,\n",
      "             6,    6,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "         [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "             1,    1,    1,   52,   52,   52,   52,   52,   52,   52,   52,\n",
      "            52,   52,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "         [   6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
      "             6,    6,    6,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "            11,   11,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "         [  52,   52,   52,   52,   52,   52,   52,   52,   52,   52,   52,\n",
      "            52,   52,   52,  100,  100,  100,  100,  100,  100,  100,  100,\n",
      "           100,  100,    6,    6,    6,    6,    6,    6,    1,    1],\n",
      "         [  11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "            11,   11,   11,   12,   12,   12,   12,   12,   12,   12,   12,\n",
      "            12,   12,   52,   52,   52,   52,   52,   52,    1,    1],\n",
      "         [  51,   51,   51,   51,   51,   51,   51,   51,  100,  100,  100,\n",
      "           100,  100,  100,  456,  456,  456,  456,  456,  456,  456,  456,\n",
      "           456,  456,   11,   11,   11,   11,   11,   11,    1,    1],\n",
      "         [  12,   12,   12,   12,   12,   12,   12,   12,   21,   21,   21,\n",
      "            21,   21,   21,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "             9,    9,  100,  100,  130,  130,  130,  130,    6,    6],\n",
      "         [1053, 1053, 1053, 1053, 1053, 1053, 1053, 1053,  513,  513,  513,\n",
      "           513,  513,  513,  727,  727,  727,  727,  727,  727,  727,  727,\n",
      "           727,  727,   12,   12,   21,   21,   21,   21,   52,   52],\n",
      "         [   2,    2,    2,    2,    2,    2,    2,    2,    8,    8,    8,\n",
      "             8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "             8,    8, 1241, 1241, 1304, 1304, 1304, 1304,   11,   11],\n",
      "         [2424, 2424, 2424, 2424, 2424, 2424, 2424, 2424,   27,   27,   27,\n",
      "            27,   27,   27,   74,   74,   74,   74,   74,   74,   74,   74,\n",
      "            74,   74,    8,    8,  789,  789,  789,  789,  130,  130],\n",
      "         [   9,    9,    9,    9,    9,    9,    9,    9,   14,   14,   14,\n",
      "            14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   14,\n",
      "            14,   14,   39,   39,    8,    8,    8,    8,   21,   21],\n",
      "         [5039, 5039, 5039, 5039, 5039, 5039, 5039, 5039,  111,  111,  111,\n",
      "           111,  111,  111,  111,  111,  111,  111,  111,  111,  111,  111,\n",
      "           111,  111, 7602, 7602, 1580, 1580, 1580, 1580, 2146, 2146]]],\n",
      "       device='cuda:0') ****\n",
      "\n",
      "\n",
      "tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) ****\n",
      "\n",
      "\n",
      "tensor([[[    6,     6,     6,  ...,     1,     1,     1],\n",
      "         [  508,   508,   508,  ...,     1,     1,     1],\n",
      "         [    3,     3,     3,  ...,     1,     1,     1],\n",
      "         ...,\n",
      "         [  111,   111,   111,  ...,     9,   553,   553],\n",
      "         [ 6007,  6007,  6007,  ...,    77,    52,    52],\n",
      "         [    4,     4,     4,  ...,     4,     4,     4]]], device='cuda:0') ****\n",
      "\n",
      "\n",
      "tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) ****\n",
      "\n",
      "\n",
      "32 ****\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in dev_data:\n",
    "    print(b[0], '****\\n\\n')\n",
    "    print(b[1], '****\\n\\n')\n",
    "    print(b[2], '****\\n\\n')\n",
    "    print(b[3], '****\\n\\n')\n",
    "    print(b[4].size(0), '****\\n\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch   0 training with lr 0.01 \n",
      "|  1000/ 2427 batches | ms/batch 115.12 | loss 1.4568 acc 0.63596875\n"
     ]
    }
   ],
   "source": [
    "for param in siamese_model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.SGD(siamese_model.linear.parameters(), lr=0.01)\n",
    "training_loop(siamese_model, 1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model, \"siamese_model_e0_lr01_v0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model = torch.load(\"./siamese_model0.500.81.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in siamese_model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for lr in [x/200+0.005 for x in range(20)]:\n",
    "    optimizer = optim.SGD(siamese_model.parameters(), lr=lr)\n",
    "    training_loop(siamese_model, 1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model, \"siamese_model_e1_lr01_v0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "optimizer = optim.SGD(siamese_model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=0.001)\n",
    "training_loop(siamese_model, epochs, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model, \"siamese_model_e10_lr1_v0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailed_a = []\n",
    "entailed_b = []\n",
    "contra_a = []\n",
    "contra_b = []\n",
    "netural_a = []\n",
    "netural_b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b,l,_ in sentence_pairs_dev:\n",
    "    if l == 0:\n",
    "        #entailed\n",
    "        entailed_a.append(a)\n",
    "        entailed_b.append(b)\n",
    "    elif l == 1:\n",
    "        contra_a.append(a)\n",
    "        contra_b.append(b)\n",
    "    else:\n",
    "        netural_a.append(a)\n",
    "        netural_b.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_from_list(model, l):\n",
    "    \"\"\"\n",
    "    Encode a list of integers that represent a sequence of tokens.  The\n",
    "    purpose is to encode a sentence or phrase.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    model : fastai language model\n",
    "    l : list\n",
    "        list of integers, representing a sequence of tokens that you want to encode`\n",
    "\n",
    "    \"\"\"\n",
    "    arr = torch.tensor(np.expand_dims(np.array(l), -1)).cuda()\n",
    "    model.reset()  # language model is stateful, so you must reset upon each prediction\n",
    "    hidden_states = model(arr)[-1][-1] # RNN Hidden Layer output is last output, and only need the last layer\n",
    "\n",
    "    #return avg-pooling, max-pooling, and last hidden state\n",
    "    return hidden_states.mean(0), hidden_states.max(0)[0], hidden_states[-1]\n",
    "\n",
    "def get_embeddings(encoder, list_list_int):\n",
    "    \"\"\"\n",
    "    Vectorize a list of sequences List[List[int]] using a fast.ai language model.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    encoder : sentence_encoder\n",
    "    list_list_int : List[List[int]]\n",
    "        A list of sequences to encode\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (avg, mean, last)\n",
    "        A tuple that returns the average-pooling, max-pooling over time steps as well as the last time step.\n",
    "    \"\"\"\n",
    "    n_rows = len(list_list_int)\n",
    "    n_dim = encoder.nhid\n",
    "    avgarr = np.empty((n_rows, n_dim))\n",
    "    maxarr = np.empty((n_rows, n_dim))\n",
    "    lastarr = np.empty((n_rows, n_dim))\n",
    "\n",
    "    for i in range(len(list_list_int)):\n",
    "        avg_, max_, last_ = make_prediction_from_list(encoder, list_list_int[i])\n",
    "        avgarr[i,:] = avg_.data.cpu().numpy()\n",
    "        maxarr[i,:] = max_.data.cpu().numpy()\n",
    "        lastarr[i,:] = last_.data.cpu().numpy()\n",
    "\n",
    "    return avgarr, maxarr, lastarr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siamese_model = torch.load('siamese_model0.500.81.pt')\n",
    "siamese_model.encoder.nhid = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailed_a_vec = get_embeddings(siamese_model.encoder, entailed_a)\n",
    "entailed_b_vec = get_embeddings(siamese_model.encoder, entailed_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "def create_nmslib_search_index(numpy_vectors):\n",
    "    \"\"\"Create search index using nmslib.\n",
    "    Parameters\n",
    "    ==========\n",
    "    numpy_vectors : numpy.array\n",
    "        The matrix of vectors\n",
    "    Returns\n",
    "    =======\n",
    "    nmslib object that has index of numpy_vectors\n",
    "    \"\"\"\n",
    "\n",
    "    search_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "    search_index.addDataPointBatch(numpy_vectors)\n",
    "    search_index.createIndex({'post': 2}, print_progress=True)\n",
    "    return search_index\n",
    "\n",
    "def percent_matching(query_vec, searchindex, k=10):\n",
    "    num_found = 0\n",
    "    num_total = len(query_vec)\n",
    "    for i in range(num_total):\n",
    "        query = query_vec[i]\n",
    "        idxs, dists = searchindex.knnQuery(query, k=k)\n",
    "        if i in idxs:\n",
    "            num_found += 1\n",
    "\n",
    "    return 100 * num_found/num_total\n",
    "\n",
    "def indexes_matching(query_vec, search_index, k=5):\n",
    "    results = []\n",
    "    for q in query_vec:\n",
    "        index_set = set()\n",
    "        idxs, dists = search_index.knnQuery(q, k=k)\n",
    "        results.append(idxs)\n",
    "    return results\n",
    " \n",
    "def percent_found(results):\n",
    "    num_found = 0\n",
    "    for i, result in enumerate(results):\n",
    "        if i in result:\n",
    "            num_found += 1\n",
    "    return (num_found/len(results))\n",
    "\n",
    "def decode_sentence(sentence):\n",
    "    result = \"\"\n",
    "    for word_idx in sentence: \n",
    "        result += f\"{itos[word_idx]} \"\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def show_similar(query_idx, matched):\n",
    "    print(decode_sentence(entailed_a[query_idx]))\n",
    "    for idx in matched:\n",
    "        print(f\"\\t{decode_sentence(entailed_b[idx])}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailed_b_avg_searchindex = create_nmslib_search_index(entailed_b_vec[0])\n",
    "entailed_b_max_searchindex = create_nmslib_search_index(entailed_b_vec[1])\n",
    "entailed_b_last_searchindex = create_nmslib_search_index(entailed_b_vec[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg = indexes_matching(entailed_a_vec[0], entailed_b_avg_searchindex, 3)\n",
    "results_max = indexes_matching(entailed_a_vec[1], entailed_b_max_searchindex, 3)\n",
    "results_last = indexes_matching(entailed_a_vec[2], entailed_b_last_searchindex, 3)\n",
    "\n",
    "num_found = 0\n",
    "for i in range(len(results_avg)):\n",
    "    if i in results_avg[i] or i in results_max[i] or i in results_last[i]:\n",
    "        num_found += 1\n",
    "print(num_found/len(results_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined = []\n",
    "for a,b,c in zip(results_avg, results_max, results_last):\n",
    "    results_combined.append(set(a).union(set(b).union(set(c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(results_combined):\n",
    "    show_similar(i, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siamese_model = torch.load('siamese_model0.500.81.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model.encoder.state_dict(), \"siamese_encoder_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "py36 fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
