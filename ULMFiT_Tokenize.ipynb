{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULMFiT + Siamese Network for Sentence Vectors\n",
    "## Part One: Tokenizing\n",
    "This notebook will tokenize the sentences from the OFFICE FAQ for use in the training of the Language Model (LM) and the InferSent network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to load fastai library\n",
    "import sys\n",
    "sys.path.append(\"/data/home/makayser/notebooks/fastai/\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import json\n",
    "import html\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from functools import partial\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils \n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import dataset, dataloader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/home/makayser/qa_local/'\n",
    "token_files = data_dir + 'token/'\n",
    "\n",
    "fp_de_cl = data_dir + \"office_help_de_cl.txt\"\n",
    "fp_de_lm = data_dir + \"office_help_de_lm.txt\"\n",
    "fp_de_clean = data_dir + \"office_help_de_clean.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58827"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and process the all the sentences, just to get the LM trained\n",
    "df = pd.read_csv(fp_de_lm, sep='\\t', lineterminator='\\r', encoding='utf-8'); len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>eid</th>\n",
       "      <th>text</th>\n",
       "      <th>apps</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ändern der Ansicht des Outlook-Kalenders</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Ändern der Ansicht des Outlook-Kalenders</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Ändern der Ansicht des Outlook-Kalenders</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Ändern der Ansicht des Outlook-Kalenders</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ändern der Ansicht des Outlook-Kalenders</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  eid                                      text     apps  length\n",
       "0   1    1  Ändern der Ansicht des Outlook-Kalenders  Outlook      40\n",
       "1   1    2  Ändern der Ansicht des Outlook-Kalenders  Outlook      40\n",
       "2   1    3  Ändern der Ansicht des Outlook-Kalenders  Outlook      40\n",
       "3   1    4  Ändern der Ansicht des Outlook-Kalenders  Outlook      40\n",
       "4   1    5  Ändern der Ansicht des Outlook-Kalenders  Outlook      40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Outlook\n",
       "6              Office\n",
       "7               Excel\n",
       "25               Lync\n",
       "42         PowerPoint\n",
       "48             Access\n",
       "51               Word\n",
       "60            Project\n",
       "127             Visio\n",
       "226        SharePoint\n",
       "493          Kalender\n",
       "543         Publisher\n",
       "685           OneNote\n",
       "744          InfoPath\n",
       "1465              NaN\n",
       "1634            Skype\n",
       "1642        Microsoft\n",
       "1817         OneDrive\n",
       "2044             Duet\n",
       "2405               MS\n",
       "3813             Sway\n",
       "4471             Mail\n",
       "13071    Communicator\n",
       "Name: apps, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apps.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58827\n"
     ]
    }
   ],
   "source": [
    "raw_text = df.text.tolist()\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the language model data into train and validation sets\n",
    "lm_train, lm_valid = sklearn.model_selection.train_test_split(raw_text, test_size=0.1)\n",
    "df_trn = pd.DataFrame(lm_train)\n",
    "df_val = pd.DataFrame(lm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'x_bos'  # beginning-of-sentence tag\n",
    "\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    x = ' '.join([out for out in x.split(' ') if len(out)<30])\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df):\n",
    "    texts = f'{BOS} ' + df[0].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)     \n",
    "    tok = Tokenizer(lang='de', n_cpus=6).process_all(texts)\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 491 ms, total: 2.39 s\n",
      "Wall time: 8.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tok_trn = np.concatenate(get_texts(df_trn))\n",
    "tok_val = np.concatenate(get_texts(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x_bos', 'benötigen', 'sie', 'hilfe?|', ..., 'können', 'in', 'einer', 'sharepoint-dokumentbibliothek'],\n",
       "      dtype='<U29')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279673"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our work\n",
    "np.save(f'{token_files}tok_trn.npy', tok_trn)\n",
    "np.save(f'{token_files}tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(f'{token_files}tok_trn.npy')\n",
    "tok_val = np.load(f'{token_files}tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 141040),\n",
       " ('sie', 134041),\n",
       " ('.', 109489),\n",
       " ('die', 74430),\n",
       " ('x_bos', 58827),\n",
       " ('der', 58361),\n",
       " ('in', 54619),\n",
       " ('und', 53781),\n",
       " ('auf', 50037),\n",
       " ('oder', 37544),\n",
       " ('von', 35697),\n",
       " ('xxup', 28005),\n",
       " ('für', 26787),\n",
       " ('können', 26091),\n",
       " ('klicken', 24133),\n",
       " ('zu', 23892),\n",
       " ('eine', 23541),\n",
       " ('das', 22125),\n",
       " ('den', 21585),\n",
       " ('einer', 21361),\n",
       " ('mit', 21318),\n",
       " ('wenn', 20678),\n",
       " ('ein', 17561),\n",
       " ('\"', 16752),\n",
       " ('werden', 16578)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(np.concatenate([tok_trn, tok_val]))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41010"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 1\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c>=min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41012"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the language model training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([stoi[p] for p in tok_trn])\n",
    "val_lm = np.array([stoi[p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "pickle.dump(itos, open(f'{token_files}itos.pkl', 'wb'))\n",
    "np.save(f'{token_files}trn_lm.npy', trn_lm)\n",
    "np.save(f'{token_files}val_lm.npy', val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41012"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results so we can pick it up from here \n",
    "itos = pickle.load(open(f'{token_files}itos.pkl', 'rb'))\n",
    "trn_lm = np.load(f'{token_files}trn_lm.npy')\n",
    "val_lm = np.load(f'{token_files}val_lm.npy')\n",
    "\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "vocab_size = len(itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_bos benötigen sie hilfe?| sicherstellen , dass sie über administratorrechte auf ihrem computer verfügen x_bos offline arbeiten in outlook x_bos sie können mithilfe der datenüberprüfung den typ der daten oder die werte einschränken , die benutzer in eine zelle eingeben . einer der häufigsten einsatzzwecke für die datenüberprüfung ist das erstellen einer dropdownliste . x_bos open another person 's exchange contacts x_bos word| x_bos erstellen eines power view-berichts in sharepoint starten von power view zum erstellen eines power view-berichts aus einer datei datenmodell in sharepoint server 2010 oder 2013 . modelle oder verbindungen zu datenmodellen , können in einer sharepoint-dokumentbibliothek "
     ]
    }
   ],
   "source": [
    "for word in val_lm[:100]:\n",
    "    print(itos[word], end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the sentence similarity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77690"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and process the all the sentences, just to get the LM trained\n",
    "df_cl = pd.read_csv(fp_de_cl, sep='\\t', lineterminator='\\r', encoding='utf-8'); len(df_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>eid</th>\n",
       "      <th>apps</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>length1</th>\n",
       "      <th>length2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Office</td>\n",
       "      <td>Ändern der Anzeigesprache und Zeitzone in Offi...</td>\n",
       "      <td>Sie können die Anzeigesprache und Zeitzone für...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Excel</td>\n",
       "      <td>Ändern der Anzeige von einem 3D-Diagramm</td>\n",
       "      <td>In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Excel</td>\n",
       "      <td>Ändern der Anzeige von einem 3D-Diagramm</td>\n",
       "      <td>In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excel</td>\n",
       "      <td>Ändern der Anzeige von einem 3D-Diagramm</td>\n",
       "      <td>In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Excel</td>\n",
       "      <td>Ändern der Anzeige von einem 3D-Diagramm</td>\n",
       "      <td>In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  eid    apps                                              sent1  \\\n",
       "0   2    1  Office  Ändern der Anzeigesprache und Zeitzone in Offi...   \n",
       "1   3    1   Excel           Ändern der Anzeige von einem 3D-Diagramm   \n",
       "2   3    2   Excel           Ändern der Anzeige von einem 3D-Diagramm   \n",
       "3   3    3   Excel           Ändern der Anzeige von einem 3D-Diagramm   \n",
       "4   3    4   Excel           Ändern der Anzeige von einem 3D-Diagramm   \n",
       "\n",
       "                                               sent2  length1  length2  \n",
       "0  Sie können die Anzeigesprache und Zeitzone für...        9       14  \n",
       "1  In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...        6      110  \n",
       "2  In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...        6      110  \n",
       "3  In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...        6      110  \n",
       "4  In einem 3D-Diagramm wie 3D-Säulen, 3D-Linie o...        6      110  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Entail(Enum):\n",
    "    Outlook = 0\n",
    "    Office = 1\n",
    "    Excel = 2\n",
    "    Lync = 3\n",
    "    PowerPoint = 4\n",
    "    Access = 5\n",
    "    Word = 6\n",
    "    Project = 7\n",
    "    Visio = 8\n",
    "    SharePoint = 9\n",
    "    Kalender = 10\n",
    "    Publisher = 11\n",
    "    OneNote = 12\n",
    "    InfoPath = 13\n",
    "    Communicator = 14\n",
    "    Skype = 15\n",
    "    Microsoft = 16\n",
    "    OneDrive = 17\n",
    "    Duet = 18\n",
    "    MS = 19\n",
    "    Sway = 20\n",
    "    Mail = 21\n",
    "\n",
    "    \n",
    "##TODO: drop NaN from categories\n",
    "def fixup_cl(data, col):\n",
    "    texts = f'{BOS} ' + data[col].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)     \n",
    "    return texts\n",
    "\n",
    "def load_sentence_pairs(df):\n",
    "    lbls = df_cl[\"apps\"].values\n",
    "    s0s = fixup_cl(df_cl, \"sent1\") #BOS+\" \"+fixup(item['sentence1'])\n",
    "    s1s = fixup_cl(df_cl, \"sent2\") #BOS+\" \"+fixup(item['sentence2'])\n",
    "    \n",
    "    labels = []\n",
    "    avg_len = []\n",
    "    for l, s0, s1 in zip(lbls,s0s,s1s):\n",
    "        average_len = (len(s0)+len(s1))/2\n",
    "        try:\n",
    "            labels.append(Entail[l].value)\n",
    "            avg_len.append(average_len)\n",
    "        except Execption as e: #KeyError\n",
    "            print(str(e))\n",
    "            pass\n",
    "        \n",
    "    s0s = Tokenizer(lang='de', n_cpus=6).process_all(s0s) #Tokenizer().proc_all_mp(partition_by_cores(s0s))\n",
    "    s1s = Tokenizer(lang='de', n_cpus=6).process_all(s1s) #Tokenizer().proc_all_mp(partition_by_cores(s1s))\n",
    "    return np.array((s0s, s1s, labels, avg_len)).transpose()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62928\n",
      "7769\n",
      "6993\n"
     ]
    }
   ],
   "source": [
    "#split the language model data into train and validation sets\n",
    "cl_train, cl_dev = sklearn.model_selection.train_test_split(df_cl, test_size=0.1)\n",
    "cl_train, cl_test = sklearn.model_selection.train_test_split(cl_train, test_size=0.1)\n",
    "df_cl_train = pd.DataFrame(cl_train); print(len(df_cl_train))\n",
    "df_cl_dev = pd.DataFrame(cl_dev); print(len(df_cl_dev))\n",
    "df_cl_test = pd.DataFrame(cl_test); print(len(df_cl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done train\n",
      "done dev\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs_train = load_sentence_pairs(df_cl_train)\n",
    "print('done train')\n",
    "sentence_pairs_dev = load_sentence_pairs(df_cl_dev)\n",
    "print('done dev')\n",
    "sentence_pairs_test = load_sentence_pairs(df_cl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{token_files}trn_office.npy', sentence_pairs_train)\n",
    "np.save(f'{token_files}dev_office.npy', sentence_pairs_dev)\n",
    "np.save(f'{token_files}test_offuce.npy', sentence_pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence_pairs):\n",
    "    for i in range(len(sentence_pairs)):\n",
    "        item = sentence_pairs[i]\n",
    "        tok0 = [stoi[p] for p in item[0]]\n",
    "        tok1 =[stoi[p] for p in item[1]]\n",
    "        sentence_pairs[i] = np.array([tok0, tok1, item[2], item[3]])\n",
    "\n",
    "tokenize(sentence_pairs_train)\n",
    "tokenize(sentence_pairs_dev)\n",
    "tokenize(sentence_pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{token_files}office_tok_train.npy', sentence_pairs_train)\n",
    "np.save(f'{token_files}office_tok_dev.npy', sentence_pairs_dev)\n",
    "np.save(f'{token_files}office_tok_test.npy', sentence_pairs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n",
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n",
      " x_bos ändern der anzeigesprache und zeitzone in office 365 business\n",
      " x_bos sie können die anzeigesprache und zeitzone für alle ihre office   365-apps und -dienste gleichzeitig ändern .\n"
     ]
    }
   ],
   "source": [
    "itos = pickle.load(open(f'{token_files}itos.pkl', 'rb'))\n",
    "\n",
    "dev = np.load(f'{token_files}office_tok_dev.npy')\n",
    "train = np.load(f'{token_files}office_tok_train.npy')\n",
    "test = np.load(f'{token_files}office_tok_test.npy')\n",
    "\n",
    "def print_sentence(s):\n",
    "    sentence = \"\"\n",
    "    for tok in s:\n",
    "        sentence += \" \"+itos[tok]\n",
    "    print(sentence)\n",
    "\n",
    "print_sentence(train[0][0])\n",
    "print_sentence(train[0][1])\n",
    "\n",
    "print_sentence(dev[0][0])\n",
    "print_sentence(dev[0][1])\n",
    "\n",
    "print_sentence(test[0][0])\n",
    "print_sentence(test[0][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36 fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
